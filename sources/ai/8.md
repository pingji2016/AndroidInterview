# TensorFlow 配置 CUDA 环境

## 完整解决方案

### 1. 首先验证 NVIDIA 驱动状态

```bash
# 检查 NVIDIA 驱动是否正常工作
nvidia-smi

# 检查驱动版本
cat /proc/driver/nvidia/version

# 检查 CUDA 驱动版本
nvidia-smi --query-gpu=driver_version --format=csv,noheader
```

如果 `nvidia-smi` 不能正常工作，请先按照之前的指导安装 NVIDIA 驱动程序。

### 2. 安装 CUDA Toolkit

TensorFlow 需要特定版本的 CUDA Toolkit。对于 TensorFlow 2.x，通常需要 CUDA 11.x：

```bash
# 下载并安装 CUDA Toolkit 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

或者使用网络安装：

```bash
# 添加 NVIDIA 包仓库
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update

# 安装 CUDA 11.8
sudo apt-get install cuda-11-8
```

### 3. 安装 cuDNN

cuDNN 是 NVIDIA 的深度学习库，TensorFlow 必须使用：

```bash
# 从 NVIDIA 官网下载 cuDNN（需要注册账号）
# 然后安装：
sudo dpkg -i libcudnn8_8.6.0.163-1+cuda11.8_amd64.deb
sudo dpkg -i libcudnn8-dev_8.6.0.163-1+cuda11.8_amd64.deb
```

### 4. 配置环境变量

将以下内容添加到 `~/.bashrc` 或 `~/.zshrc`：

```bash
export PATH=/usr/local/cuda-11.8/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
export CUDA_HOME=/usr/local/cuda-11.8
```

然后加载配置：

```bash
source ~/.bashrc
```

### 5. 验证 CUDA 安装

```bash
# 检查 CUDA 编译器
nvcc --version

# 检查 CUDA 运行时版本
/usr/local/cuda/bin/cuda-install-samples-11.8.sh .
cd NVIDIA_CUDA-11.8_Samples/1_Utilities/deviceQuery
make
./deviceQuery
```

### 6. 安装 TensorFlow 的 GPU 版本

```bash
# 确保安装的是 tensorflow-gpu
pip uninstall tensorflow tensorflow-cpu -y
pip install tensorflow[and-cuda]  # 或者 tensorflow-gpu
```

### 7. 验证 TensorFlow GPU 支持

创建测试脚本 `test_gpu.py`：

```python
import tensorflow as tf

print("TensorFlow version:", tf.__version__)
print("CUDA available:", tf.test.is_built_with_cuda())
print("GPU available:", tf.config.list_physical_devices('GPU'))

# 列出所有可用设备
print("\nAll physical devices:")
for device in tf.config.list_physical_devices():
    print(f"  {device.device_type}: {device.name}")

# 尝试创建一个简单的计算来测试 GPU
if tf.config.list_physical_devices('GPU'):
    print("\nTesting GPU computation...")
    with tf.device('/GPU:0'):
        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
        b = tf.constant([[1.0, 1.0], [0.0, 1.0]])
        c = tf.matmul(a, b)
        print("Matrix multiplication result:")
        print(c.numpy())
else:
    print("\nNo GPU found, using CPU...")
```

运行测试：

```bash
python test_gpu.py
```

### 8. 常见问题解决

如果仍然有问题，尝试：

```bash
# 检查库文件链接
sudo ldconfig /usr/local/cuda/lib64

# 检查库文件是否存在
ls -la /usr/local/cuda/lib64/libcudart.so*
ls -la /usr/local/cuda/lib64/libcudnn.so*

# 如果库文件链接有问题，重新创建链接
sudo ln -sf /usr/local/cuda-11.8/lib64/libcudart.so.11.0 /usr/local/cuda/lib64/libcudart.so.11.0
```

### 9. 检查系统兼容性

```bash
# 检查 GCC 版本（应该与 CUDA 兼容）
gcc --version

# 检查内核版本
uname -r

# 检查 NVIDIA 模块是否加载
lsmod | grep nvidia
```

### 10. 重启系统

完成所有安装后，重启系统：

```bash
sudo reboot
```

## 版本兼容性参考

- **TensorFlow 2.13**: CUDA 11.8, cuDNN 8.6
- **TensorFlow 2.12**: CUDA 11.8, cuDNN 8.6  
- **TensorFlow 2.11**: CUDA 11.2, cuDNN 8.1

请根据您安装的 TensorFlow 版本选择对应的 CUDA 和 cuDNN 版本。

完成这些步骤后，TensorFlow 应该能够正确检测并使用您的 GPU 了。