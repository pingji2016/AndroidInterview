å¥½çš„ï¼Œæˆ‘æ¥è¯¦ç»†è®²è§£å†³ç­–æ ‘çš„å·¥ä½œåŸç†ï¼Œç‰¹åˆ«æ˜¯å®ƒåœ¨å¤šç»´åº¦æ•°æ®ä¸Šçš„å·¥ä½œæ–¹å¼ã€‚

## ğŸŒ³ å†³ç­–æ ‘åŸºæœ¬åŸç†

å†³ç­–æ ‘æ˜¯ä¸€ç§æ¨¡ä»¿äººç±»å†³ç­–è¿‡ç¨‹çš„æ ‘å½¢ç»“æ„ï¼Œé€šè¿‡ä¸€ç³»åˆ—"å¦‚æœ-é‚£ä¹ˆ"è§„åˆ™æ¥è¿›è¡Œé¢„æµ‹ã€‚

### æ ¸å¿ƒæ€æƒ³ï¼šåˆ†è€Œæ²»ä¹‹
å°†å¤æ‚çš„å¤šç»´åº¦æ•°æ®ç©ºé—´ï¼Œé€’å½’åœ°åˆ’åˆ†ä¸ºæ›´ç®€å•ã€æ›´çº¯å‡€çš„å­åŒºåŸŸã€‚

## ğŸ¯ å†³ç­–æ ‘å¦‚ä½•å·¥ä½œï¼ˆä¸‰æ­¥æµç¨‹ï¼‰

### 1. **ç‰¹å¾é€‰æ‹©** - æ‰¾åˆ°æœ€ä½³åˆ†è£‚ç‚¹
```python
# ä¼ªä»£ç ï¼šé€‰æ‹©æœ€ä½³åˆ†è£‚ç‰¹å¾
def find_best_split(data, features):
    best_feature = None
    best_threshold = None
    best_gain = -1
    
    for feature in features:
        for threshold in possible_thresholds:
            gain = calculate_information_gain(data, feature, threshold)
            if gain > best_gain:
                best_gain = gain
                best_feature = feature
                best_threshold = threshold
    
    return best_feature, best_threshold
```

### 2. **èŠ‚ç‚¹åˆ†è£‚** - æ ¹æ®è§„åˆ™åˆ’åˆ†æ•°æ®
### 3. **é€’å½’æ„å»º** - å¯¹å­èŠ‚ç‚¹é‡å¤è¿‡ç¨‹

## ğŸ“Š åœ¨å¤šç»´åº¦æ•°æ®ä¸Šçš„å·¥ä½œæ–¹å¼

### ç¤ºä¾‹ï¼š Titanicæ•°æ®é›†ï¼ˆ4ä¸ªç‰¹å¾ï¼‰
| Age | Fare | Sex | Pclass | Survived |
|-----|------|-----|--------|----------|
| 22 | 7.25 | male | 3 | 0 |
| 38 | 71.28 | female | 1 | 1 |
| 26 | 7.92 | female | 3 | 1 |
| 35 | 53.1 | female | 1 | 1 |
| 28 | 8.05 | male | 3 | 0 |

### ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©æ ¹èŠ‚ç‚¹åˆ†è£‚ç‰¹å¾
å†³ç­–æ ‘ä¼šè®¡ç®—æ¯ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼š

1. **æŒ‰æ€§åˆ«åˆ†è£‚**ï¼š
   - ç”·æ€§ï¼šå­˜æ´»ç‡ 20%
   - å¥³æ€§ï¼šå­˜æ´»ç‡ 80%
   - ä¿¡æ¯å¢ç›Šé«˜ âœ“

2. **æŒ‰ç¥¨ä»·åˆ†è£‚**ï¼š
   - ç¥¨ä»·<50ï¼šå­˜æ´»ç‡ 40%
   - ç¥¨ä»·â‰¥50ï¼šå­˜æ´»ç‡ 100%
   - ä¿¡æ¯å¢ç›Šä¸­ç­‰

3. **æŒ‰å¹´é¾„åˆ†è£‚**ï¼š
   - ä¿¡æ¯å¢ç›Šè¾ƒä½

**é€‰æ‹©"Sex"ä½œä¸ºæ ¹èŠ‚ç‚¹åˆ†è£‚ç‰¹å¾**

### ç¬¬äºŒæ­¥ï¼šæ„å»ºæ ‘ç»“æ„
```
         [æ ¹èŠ‚ç‚¹: å…¨éƒ¨æ•°æ®]
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
   Sex == male     Sex == female
       â”‚               â”‚
   [å­˜æ´»ç‡20%]     [å­˜æ´»ç‡80%]
```

### ç¬¬ä¸‰æ­¥ï¼šç»§ç»­åˆ†è£‚ä¸çº¯çš„èŠ‚ç‚¹
å¯¹ç”·æ€§èŠ‚ç‚¹è¿›ä¸€æ­¥åˆ†è£‚ï¼š

```python
# åœ¨ç”·æ€§å­é›†ä¸­å¯»æ‰¾æœ€ä½³åˆ†è£‚
male_data = data[data['Sex'] == 'male']
best_feature, best_threshold = find_best_split(male_data, ['Age', 'Fare', 'Pclass'])

# å‡è®¾å‘ç°"Fare"æ˜¯æœ€å¥½çš„åˆ†è£‚ç‰¹å¾
# ç¥¨ä»· < 10 â†’ å­˜æ´»ç‡ 10%
# ç¥¨ä»· â‰¥ 10 â†’ å­˜æ´»ç‡ 30%
```

## ğŸ¯ åˆ†è£‚å‡†åˆ™çš„æ•°å­¦åŸç†

### 1. **ä¿¡æ¯å¢ç›Šï¼ˆInformation Gainï¼‰**
åŸºäºç†µçš„å‡å°‘æ¥é€‰æ‹©ç‰¹å¾ï¼š

```python
def information_gain(parent_entropy, children_entropies, children_weights):
    # çˆ¶èŠ‚ç‚¹ç†µ - å­èŠ‚ç‚¹ç†µçš„åŠ æƒå¹³å‡
    weighted_child_entropy = sum(w * e for w, e in zip(children_weights, children_entropies))
    return parent_entropy - weighted_child_entropy

def entropy(labels):
    from collections import Counter
    counts = Counter(labels)
    proportions = [count / len(labels) for count in counts.values()]
    return -sum(p * math.log2(p) for p in proportions if p > 0)
```

### 2. **åŸºå°¼ä¸çº¯åº¦ï¼ˆGini Impurityï¼‰**
```python
def gini_impurity(labels):
    from collections import Counter
    counts = Counter(labels)
    proportions = [count / len(labels) for count in counts.values()]
    return 1 - sum(p**2 for p in proportions)
```

## ğŸ” å¤šç»´åº¦åˆ†è£‚çš„å¯è§†åŒ–

å‡è®¾åªæœ‰ä¸¤ä¸ªç‰¹å¾ï¼šAgeå’ŒFare

```
Fare
  â†‘
  â”‚   å†³ç­–è¾¹ç•Œ: Fare = 50
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   â”‚             â”‚             â”‚
  â”‚   â”‚  å¤§éƒ¨åˆ†æ­»äº¡  â”‚  å¤§éƒ¨åˆ†å­˜æ´»  â”‚
  â”‚   â”‚             â”‚             â”‚
  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   â”‚             â”‚             â”‚
  â”‚   â”‚  æ··åˆåŒºåŸŸ    â”‚  éœ€è¦è¿›ä¸€æ­¥  â”‚
  â”‚   â”‚             â”‚  åˆ†è£‚       â”‚
  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â†’ Age
```

## âš™ï¸ å®é™…åˆ†è£‚è¿‡ç¨‹ç¤ºä¾‹

```python
# å®é™…å†³ç­–æ ‘å¯èƒ½æ„å»ºçš„è§„åˆ™é›†
rules = [
    "å¦‚æœ Sex == 'female' â†’ å¤§æ¦‚ç‡å­˜æ´»(80%)",
    "å¦‚æœ Sex == 'male' ä¸” Fare < 10 â†’ å¤§æ¦‚ç‡æ­»äº¡(90%)",
    "å¦‚æœ Sex == 'male' ä¸” Fare â‰¥ 10 ä¸” Age < 18 â†’ è¾ƒå¯èƒ½å­˜æ´»(60%)",
    "å¦‚æœ Sex == 'male' ä¸” Fare â‰¥ 10 ä¸” Age â‰¥ 18 â†’ è¾ƒå¯èƒ½æ­»äº¡(70%)"
]
```

## ğŸª å¤šç»´åº¦å¤„ç†çš„ä¼˜åŠ¿

### 1. **è‡ªåŠ¨ç‰¹å¾é€‰æ‹©**
- å¿½ç•¥ä¸ç›¸å…³ç‰¹å¾ï¼ˆå¦‚ä¹˜å®¢IDï¼‰
- é‡ç‚¹å…³æ³¨æœ‰é¢„æµ‹åŠ›çš„ç‰¹å¾

### 2. **å¤„ç†æ··åˆç±»å‹ç‰¹å¾**
```python
# åŒæ—¶å¤„ç†æ•°å€¼å’Œç±»åˆ«ç‰¹å¾
numerical_features = ['Age', 'Fare']    # æ•°å€¼å‹ï¼šå¯»æ‰¾é˜ˆå€¼åˆ†è£‚
categorical_features = ['Sex', 'Pclass'] # ç±»åˆ«å‹ï¼šæŒ‰ç±»åˆ«åˆ†è£‚
```

### 3. **æ•æ‰ç‰¹å¾äº¤äº’**
- å‘ç°å¦‚"å¥³æ€§ä¸”å¤´ç­‰èˆ±"çš„é«˜å­˜æ´»ç»„åˆ
- è‡ªåŠ¨è¯†åˆ«é‡è¦çš„ç‰¹å¾ç»„åˆ

## ğŸ”§ å†³ç­–æ ‘çš„æ•°å­¦ä¼˜åŒ–

### æœ€ä½³åˆ†è£‚ç‚¹æœç´¢ç®—æ³•
```python
def find_numeric_split(feature_values, labels):
    # å¯¹ç‰¹å¾å€¼æ’åº
    sorted_indices = np.argsort(feature_values)
    sorted_features = feature_values[sorted_indices]
    sorted_labels = labels[sorted_indices]
    
    best_gain = -1
    best_threshold = None
    
    # å°è¯•æ‰€æœ‰å¯èƒ½çš„åˆ†è£‚ç‚¹
    for i in range(1, len(sorted_features)):
        if sorted_features[i] != sorted_features[i-1]:
            threshold = (sorted_features[i] + sorted_features[i-1]) / 2
            
            left_labels = sorted_labels[:i]
            right_labels = sorted_labels[i:]
            
            gain = information_gain(entropy(labels), 
                                   [entropy(left_labels), entropy(right_labels)],
                                   [len(left_labels)/len(labels), len(right_labels)/len(labels)])
            
            if gain > best_gain:
                best_gain = gain
                best_threshold = threshold
    
    return best_threshold, best_gain
```

## ğŸ’¡ ä¸ºä»€ä¹ˆå†³ç­–æ ‘é€‚åˆå¤šç»´åº¦æ•°æ®ï¼Ÿ

1. **å¯è§£é‡Šæ€§å¼º**ï¼šæ¯ä¸ªåˆ†è£‚éƒ½æœ‰æ˜ç¡®å«ä¹‰
2. **æ— éœ€é¢„å¤„ç†**ï¼šè‡ªåŠ¨å¤„ç†æ•°å€¼å’Œç±»åˆ«ç‰¹å¾
3. **ç‰¹å¾é‡è¦æ€§**ï¼šå¯ä»¥è¯„ä¼°æ¯ä¸ªç‰¹å¾çš„è´¡çŒ®åº¦
4. **å¤„ç†éçº¿æ€§å…³ç³»**ï¼šå¯ä»¥æ•æ‰å¤æ‚æ¨¡å¼

## ğŸš€ å®é™…åº”ç”¨å»ºè®®

```python
# åˆ›å»ºå¯è§£é‡Šçš„å†³ç­–æ ‘
model = tfdf.keras.CartModel(
    max_depth=5,        # æ§åˆ¶å¤æ‚åº¦
    min_examples=10,    # é˜²æ­¢è¿‡æ‹Ÿåˆ
    verbose=0
)

# è®­ç»ƒåå¯ä»¥æŸ¥çœ‹å†³ç­–è§„åˆ™
model.fit(train_data)
print("å†³ç­–æ ‘æ·±åº¦:", model.make_inspector().depth())
print("ç‰¹å¾é‡è¦æ€§:", model.make_inspector().variable_importances())
```

å†³ç­–æ ‘é€šè¿‡é€’å½’åœ°åœ¨å¤šç»´åº¦æ•°æ®ä¸­æ‰¾åˆ°æœ€ä½³åˆ†è£‚ç‚¹ï¼Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—ç®€å•å†³ç­–ï¼Œä»è€Œå®ç°å¯¹å¤æ‚æ¨¡å¼çš„æœ‰æ•ˆå­¦ä¹ ã€‚


å¥½çš„ï¼Œæˆ‘æ¥è¯¦ç»†è®²è§£å†³ç­–æ ‘ä¸­å„ä¸ªå‚æ•°çš„ä½œç”¨å’Œè°ƒå‚å»ºè®®ï¼š

## ğŸŒ³ å†³ç­–æ ‘æ ¸å¿ƒå‚æ•°è¯¦è§£

### 1. **æ ‘ç»“æ„æ§åˆ¶å‚æ•°**

#### `max_depth` - æœ€å¤§æ·±åº¦
```python
model = tfdf.keras.CartModel(max_depth=5)
```
- **ä½œç”¨**ï¼šé™åˆ¶æ ‘çš„æœ€å¤§ç”Ÿé•¿æ·±åº¦
- **å½±å“**ï¼š
  - â¬†ï¸ å€¼å¤ªå¤§ï¼šè¿‡æ‹Ÿåˆé£é™©é«˜ï¼Œæ¨¡å‹å¤æ‚
  - â¬‡ï¸ å€¼å¤ªå°ï¼šæ¬ æ‹Ÿåˆï¼Œæ¨¡å‹è¿‡äºç®€å•
- **å»ºè®®**ï¼šä»3-10å¼€å§‹å°è¯•ï¼Œå¸¸ç”¨5-8

#### `min_examples` - èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
```python
model = tfdf.keras.CartModel(min_examples=10)
```
- **ä½œç”¨**ï¼šåˆ†è£‚èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°é‡
- **å½±å“**ï¼š
  - â¬†ï¸ å€¼å¤§ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ³›åŒ–æ€§å¥½
  - â¬‡ï¸ å€¼å°ï¼šå¯èƒ½è¿‡æ‹Ÿåˆï¼Œå¯¹å™ªå£°æ•æ„Ÿ
- **å»ºè®®**ï¼šå¯¹äºå¤§æ•°æ®é›†ç”¨è¾ƒå°å€¼(5-20)ï¼Œå°æ•°æ®é›†ç”¨è¾ƒå¤§å€¼(20-50)

### 2. **åˆ†è£‚å‡†åˆ™å‚æ•°**

#### `split_axis` - åˆ†è£‚è½´ç­–ç•¥
```python
model = tfdf.keras.CartModel(split_axis="SPARSE_OBLIQUE")
```
- **é€‰é¡¹**ï¼š
  - `"AXIS_ALIGNED"`ï¼šæ ‡å‡†è½´å¯¹é½åˆ†è£‚ï¼ˆé»˜è®¤ï¼‰
  - `"SPARSE_OBLIQUE"`ï¼šç¨€ç–æ–œåˆ†è£‚ï¼Œèƒ½æ•æ‰æ›´å¤æ‚å…³ç³»
- **å»ºè®®**ï¼šå¤§æ•°æ®é›†ç”¨æ–œåˆ†è£‚ï¼Œå°æ•°æ®é›†ç”¨æ ‡å‡†åˆ†è£‚

### 3. **ç‰¹å¾å¤„ç†å‚æ•°**

#### `categorical_algorithm` - åˆ†ç±»ç‰¹å¾ç®—æ³•
```python
model = tfdf.keras.CartModel(categorical_algorithm="RANDOM")
```
- **é€‰é¡¹**ï¼š
  - `"CART"`ï¼šCARTç®—æ³•å¤„ç†
  - `"RANDOM"`ï¼šéšæœºé€‰æ‹©åˆ†è£‚ç‚¹
  - `"ONE_HOT"`ï¼šç‹¬çƒ­ç¼–ç 
- **å»ºè®®**ï¼š`"RANDOM"`é€šå¸¸æ•ˆæœè¾ƒå¥½

### 4. **æ­£åˆ™åŒ–å‚æ•°**

#### `shrinkage` - å­¦ä¹ ç‡ï¼ˆä»…GBMï¼‰
```python
model = tfdf.keras.GradientBoostedTreesModel(shrinkage=0.1)
```
- **ä½œç”¨**ï¼šæ§åˆ¶æ¯æ£µæ ‘çš„è´¡çŒ®ç¨‹åº¦
- **å½±å“**ï¼š
  - â¬†ï¸ å€¼å°(0.01-0.1)ï¼šå­¦ä¹ æ…¢ï¼Œéœ€è¦æ›´å¤šæ ‘ï¼Œä½†æ›´ç²¾ç¡®
  - â¬‡ï¸ å€¼å¤§(0.1-0.3)ï¼šå­¦ä¹ å¿«ï¼Œéœ€è¦è¾ƒå°‘æ ‘
- **å»ºè®®**ï¼šå¸¸ç”¨0.05-0.2

### 5. **é‡‡æ ·å‚æ•°**

#### `subsample` - æ ·æœ¬é‡‡æ ·æ¯”ä¾‹
```python
model = tfdf.keras.RandomForestModel(subsample=0.8)
```
- **ä½œç”¨**ï¼šæ¯æ£µæ ‘ä½¿ç”¨çš„è®­ç»ƒæ ·æœ¬æ¯”ä¾‹
- **å½±å“**ï¼šå‡å°‘è¿‡æ‹Ÿåˆï¼Œå¢åŠ å¤šæ ·æ€§
- **å»ºè®®**ï¼š0.7-0.9

#### `num_candidate_attributes_ratio` - ç‰¹å¾é‡‡æ ·æ¯”ä¾‹
```python
model = tfdf.keras.RandomForestModel(num_candidate_attributes_ratio=0.5)
```
- **ä½œç”¨**ï¼šæ¯æ¬¡åˆ†è£‚æ—¶è€ƒè™‘çš„ç‰¹å¾æ¯”ä¾‹
- **å½±å“**ï¼šå¢åŠ æ ‘é—´å¤šæ ·æ€§ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- **å»ºè®®**ï¼šå¯¹äºé«˜ç»´æ•°æ®ç”¨0.3-0.5ï¼Œä½ç»´æ•°æ®ç”¨0.5-0.8

## ğŸ¯ å‚æ•°è°ƒä¼˜ç­–ç•¥

### é˜²æ­¢è¿‡æ‹Ÿåˆçš„ç»„åˆ
```python
# ä¿å®ˆé…ç½® - é˜²æ­¢è¿‡æ‹Ÿåˆ
model = tfdf.keras.CartModel(
    max_depth=5,              # é™åˆ¶æ·±åº¦
    min_examples=20,          # éœ€è¦è¶³å¤Ÿæ ·æœ¬æ‰åˆ†è£‚
    subsample=0.7,            # æ ·æœ¬é‡‡æ ·
    num_candidate_attributes_ratio=0.6  # ç‰¹å¾é‡‡æ ·
)
```

### è¿½æ±‚ç²¾åº¦çš„ç»„åˆ
```python
# æ¿€è¿›é…ç½® - è¿½æ±‚è®­ç»ƒç²¾åº¦
model = tfdf.keras.CartModel(
    max_depth=10,             # æ›´æ·±
    min_examples=5,           # æ›´å®¹æ˜“åˆ†è£‚
    subsample=1.0,            # ä½¿ç”¨å…¨éƒ¨æ ·æœ¬
    num_candidate_attributes_ratio=1.0  # ä½¿ç”¨å…¨éƒ¨ç‰¹å¾
)
```

## ğŸ“Š å‚æ•°å½±å“æ€»ç»“è¡¨

| å‚æ•° | å€¼å¢å¤§æ•ˆæœ | å€¼å‡å°æ•ˆæœ | æ¨èèŒƒå›´ |
|------|------------|------------|----------|
| `max_depth` | ğŸ“ˆ å¤æ‚åº¦â†‘ è¿‡æ‹Ÿåˆâ†‘ | ğŸ“‰ å¤æ‚åº¦â†“ æ¬ æ‹Ÿåˆâ†‘ | 3-10 |
| `min_examples` | ğŸ“ˆ æ³›åŒ–æ€§â†‘ è¿‡æ‹Ÿåˆâ†“ | ğŸ“‰ çµæ•åº¦â†‘ è¿‡æ‹Ÿåˆâ†‘ | 5-50 |
| `shrinkage` | ğŸ“ˆ å­¦ä¹ å¿« æ ‘å°‘ | ğŸ“‰ å­¦ä¹ æ…¢ æ ‘å¤š | 0.05-0.2 |
| `subsample` | ğŸ“ˆ å¤šæ ·æ€§â†“ | ğŸ“‰ å¤šæ ·æ€§â†‘ è¿‡æ‹Ÿåˆâ†“ | 0.7-0.9 |
| `num_candidate_attributes_ratio` | ğŸ“ˆ å¤šæ ·æ€§â†“ | ğŸ“‰ å¤šæ ·æ€§â†‘ | 0.3-0.8 |

## ğŸ”§ å®é™…è°ƒå‚ç¤ºä¾‹

```python
def tune_decision_tree(X_train, y_train, X_val, y_val):
    best_score = 0
    best_params = {}
    
    # å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
    for max_depth in [3, 5, 7, 10]:
        for min_examples in [5, 10, 20]:
            model = tfdf.keras.CartModel(
                max_depth=max_depth,
                min_examples=min_examples,
                verbose=0
            )
            model.fit(X_train, y_train)
            score = model.evaluate(X_val, y_val)
            
            if score > best_score:
                best_score = score
                best_params = {'max_depth': max_depth, 'min_examples': min_examples}
    
    return best_params, best_score
```

## ğŸ’¡ å®ç”¨å»ºè®®

1. **å…ˆä»é»˜è®¤å‚æ•°å¼€å§‹**ï¼Œç„¶åé€æ­¥è°ƒæ•´
2. **ä½¿ç”¨äº¤å‰éªŒè¯**æ¥è¯„ä¼°å‚æ•°æ•ˆæœ
3. `max_depth` å’Œ `min_examples` æ˜¯æœ€é‡è¦çš„å‚æ•°
4. å¯¹äº**å°æ•°æ®é›†**ï¼Œä½¿ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–
5. å¯¹äº**å¤§æ•°æ®é›†**ï¼Œå¯ä»¥é€‚å½“æ”¾å®½é™åˆ¶

ç†è§£è¿™äº›å‚æ•°çš„ä½œç”¨å¯ä»¥å¸®åŠ©æ‚¨æ›´å¥½åœ°æ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚